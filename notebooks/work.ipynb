{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 1\n",
    "# in your notebook cell\n",
    "import sys\n",
    "# path relative to your notebook\n",
    "sys.path.append(\"/Users/joel/Desktop/daimil10/capstone_1/DC-Metro-Crime-Data-2007---2017/src\")\n",
    "# import as usual\n",
    "import functions\n",
    "\n",
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file in and drop first two rows\n",
    "# First two rows seem to make like no sense with the rest of this data set\n",
    "df = functions.read_file('/Users/joel/Desktop/daimil10/capstone_1/DC-Metro-Crime-Data-2007---2017/data/dc_crime_add_vars.csv')\n",
    "df = df.drop(['Unnamed: 0', 'X'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describing the Dataset 1\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describing the Dataset 2\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describing the Dataset 3\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describing the Dataset 4\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describing the Dataset 5\n",
    "missing_v = df.isnull().sum()\n",
    "missing_v\n",
    "\n",
    "# new dataframe of al missing values\n",
    "data = {\n",
    "    'DISTRICT': [200],\n",
    "    'PSA': [251],\n",
    "    'NEIGHBORHOOD_CLUSTER': [4705],\n",
    "    'BLOCK_GROUP': [1091],\n",
    "    'CENSUS_TRACT': [1091],\n",
    "    'VOTING_PRECINCT': [84],\n",
    "    'START_DATE': [13],\n",
    "    'END_DATE': [11651],\n",
    "    'XBLOCK': [0],\n",
    "    'YBLOCK': [0],\n",
    "    'date': [0],\n",
    "    'year': [0],\n",
    "    'month': [0],\n",
    "    'day': [0],\n",
    "    'hour': [0],\n",
    "    'minute': [0],\n",
    "    'second': [0]\n",
    "}\n",
    "\n",
    "# show the missing data\n",
    "df_bar = pd.DataFrame(data)\n",
    "plt.figure(figsize=(12, 6))\n",
    "df_bar.plot(kind='bar', edgecolor='black')\n",
    "\n",
    "plt.xlabel('Col Name')\n",
    "plt.ylabel('Missing Values')\n",
    "plt.title('Missing Values in Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describing the Dataset 6\n",
    "# Went from 342867 to 325340 = 17527 removed which is roughly 5% of the dataset \n",
    "df = functions.drop_rows_with_missing_data(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describing the Dataset 7\n",
    "functions.describe_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describing the Dataset 8\n",
    "functions.get_column_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can use this is need to or can slice the other df accordingly\n",
    " \n",
    "# Slice df to only include the offense of homicide\n",
    "\n",
    "# Convert datetimes\n",
    "\n",
    "# Make new start and end hour column\n",
    "df_2 = df[df['OFFENSE']=='HOMICIDE']\n",
    "df_2['START_DATE'] = pd.to_datetime(df_2['START_DATE'])\n",
    "df_2['END_DATE'] = pd.to_datetime(df_2['END_DATE'])\n",
    "df_2['start_hour'] = df_2['START_DATE'].dt.hour\n",
    "df_2['end_hour'] = df_2['START_DATE'].dt.hour\n",
    "df_2 = df_2.drop('hour', axis=1)\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can use this is need to or can slice the other df accordingly \n",
    "\n",
    "# 1100 rows now\n",
    "hom_df = df_2\n",
    "\n",
    "# Slicing df one last time to get only my desired columns\n",
    "hom_df = hom_df[['REPORT_DAT',\n",
    "                'SHIFT',\n",
    "                'OFFENSE',\n",
    "                'METHOD',\n",
    "                'BLOCK',\n",
    "                'DISTRICT',\n",
    "                'PSA',\n",
    "                'WARD',\n",
    "                'ANC',\n",
    "                'NEIGHBORHOOD_CLUSTER',\n",
    "                'BLOCK_GROUP',\n",
    "                'VOTING_PRECINCT',\n",
    "                'START_DATE',\n",
    "                'END_DATE',\n",
    "                'XBLOCK',\n",
    "                'YBLOCK',\n",
    "                'date',\n",
    "                'year',\n",
    "                'start_hour',\n",
    "                'end_hour',\n",
    "                'crimetype']]\n",
    "\n",
    "#Show that it worked\n",
    "hom_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have homicides increased over this decade?\n",
    "# Line Chart\n",
    "\n",
    "from matplotlib import style\n",
    "\n",
    "homicides_df = df[df['OFFENSE'] == 'HOMICIDE']\n",
    "# Group the data by year and count the number of homicides per year\n",
    "homicides_by_year = homicides_df.groupby('year').size()\n",
    "\n",
    "plotter = functions.Plot()\n",
    "plotter.line_chart(homicides_by_year, 'Year', 'Homicides', 'Number of Homicides by Year: 2008 - 2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which wards / neighborhoods had the highest number of homicides?\n",
    "# Bar Chart\n",
    "\n",
    "# Filter the DataFrame for homicides\n",
    "homicides_df = df[df['OFFENSE'] == 'HOMICIDE']\n",
    "\n",
    "# Get homicides by district value counts and sort values\n",
    "homicides_by_location = homicides_df['WARD'].value_counts().sort_values()\n",
    "\n",
    "plotter.bar_chart(homicides_by_location, 'Ward', 'Homicides', 'Number of Homicides by Ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there any correlation between the time of the day and the occurrence of homicides?\n",
    "# Heat Map\n",
    "\n",
    "# Extract the hour from the 'REPORT_DAT' column\n",
    "df['Time_of_Day'] = pd.to_datetime(df['REPORT_DAT']).dt.hour\n",
    "\n",
    "# Create a binary(dummy) column for the cat columns\n",
    "df['Homicide'] = df['OFFENSE'].apply(lambda x: 1 if 'HOMICIDE' in x else 0)\n",
    "df['Shift_Evening'] = df['SHIFT'].apply(lambda x: 1 if 'EVENING' in x else 0)\n",
    "df['Shift_Midnight'] = df['SHIFT'].apply(lambda x: 1 if 'MIDNIGHT' in x else 0)\n",
    "\n",
    "# Select the columns of interest\n",
    "correlation_df= df[['Time_of_Day', 'Homicide', 'Shift_Evening', 'Shift_Midnight']]\n",
    "corr_matrix = correlation_df.corr()\n",
    "\n",
    "plotter.heatmap(corr_matrix, 'Matrix Columns', 'Matrix Column', 'Correlation Heatmap: Homicide & Time of Day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are homicides more likely to occur with a gun or a knife? \n",
    "# Stacked Plot\n",
    "\n",
    "#replace method\n",
    "df['OFFENSE'] = df['OFFENSE'].replace('ASSAULT W/DANGEROUS WEAPON', 'ASSAULT W/ WEAPON')\n",
    "\n",
    "# Select list of violent offenses\n",
    "offenses = ['HOMICIDE', 'ROBBERY', 'ASSAULT W/ WEAPON', 'BURGLARY']\n",
    "\n",
    "# Filter the DataFrame using isin cause i keep getting value error? \n",
    "filtered_df = df[df['OFFENSE'].isin(offenses)]\n",
    "\n",
    "# Group the data by offense and method, and count\n",
    "# .size()is used after grouping the data to count the number of occurrences \n",
    "# for each group. It returns a Series or DataFrame with the counts.\n",
    "# .unstack() is applied to a hierarchical index (such as the result of a groupby operation) \n",
    "# and reshapes the data by \"unstacking\" one level of the index to create columns.\n",
    "grouped_data = filtered_df.groupby(['OFFENSE', 'METHOD']).size().unstack()\n",
    "\n",
    "# Calculate the proportions for each method within each offense\n",
    "grouped_data_proportions = grouped_data.div(grouped_data.sum(axis=1), axis=0) * 100  # Multiply by 100 to get percentages\n",
    "\n",
    "plotter.stacked(grouped_data_proportions, 'Offense', 'Proportion(%)', 'Proportion of Offenses by Method: 2007 - 2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra: Folium Experiment?\n",
    "\n",
    "\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "# Filter the DataFrame to include only homicides\n",
    "homicides_df = df[df['OFFENSE'] == 'HOMICIDE']\n",
    "\n",
    "# Group the data by ward and count the number of homicides in each ward\n",
    "PSA_homicide_counts = homicides_df['WARD'].value_counts()\n",
    "\n",
    "# Find the ward with the highest amount of homicides\n",
    "PSA_with_highest_homicides = PSA_homicide_counts.idxmax()\n",
    "\n",
    "# Filter the DataFrame to include only the data for the ward with the highest amount of homicides\n",
    "PSA_homicides_df = homicides_df[homicides_df['WARD'] == PSA_with_highest_homicides]\n",
    "\n",
    "# Create a map centered on Washington D.C.\n",
    "map_homicides = folium.Map(location=[38.9072, -77.0369], zoom_start=12)\n",
    "\n",
    "# Generate coordinates for heatmap from the filtered DataFrame\n",
    "heat_data = PSA_homicides_df[['YBLOCK', 'XBLOCK']].values\n",
    "\n",
    "#for legend\n",
    "num_66 = homicides_df['WARD'].value_counts()[8]\n",
    "\n",
    "legend_html = f'''\n",
    "                <div style=\"position: fixed; \n",
    "                            bottom: 50px; left: 50px; width: 120px; height: 60px; \n",
    "                            background-color: rgba(255, 255, 255, 0.9); z-index:9999; \n",
    "                            font-size:14px;border-radius: 5px;\n",
    "                            \">\n",
    "                <strong>WARD 8</strong><br>\n",
    "                Total Homicides: {num_66}\n",
    "                </div>\n",
    "                '''\n",
    "\n",
    "legend_div = folium.features.DivIcon(\n",
    "    icon_size=(120, 80),\n",
    "    icon_anchor=(10, 10),\n",
    "    html=legend_html\n",
    ")\n",
    "\n",
    "folium.Marker(\n",
    "    location=[38.8457, -77.0097],  # Adjust the location as per your preference\n",
    "    icon=legend_div,\n",
    ").add_to(map_homicides)\n",
    "\n",
    "# Add the heatmap layer to the map\n",
    "HeatMap(heat_data).add_to(map_homicides)\n",
    "\n",
    "# Display the map\n",
    "map_homicides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_66 = homicides_df['PSA'].value_counts()[604]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
